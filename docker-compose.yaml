services:
  mysql:
    image: mysql:8.0
    container_name: de_mysql
    volumes:
      - ./dataset:/tmp/dataset
      - ./load_dataset_into_mysql:/tmp/load_dataset
    ports:
      - "3307:3306"
    environment:
      - MYSQL_DATABASE=${MYSQL_DATABASE}
      - MYSQL_ROOT_USER=${MYSQL_ROOT_USER}
      - MYSQL_ROOT_PASSWORD=${MYSQL_ROOT_PASSWORD}
      - MYSQL_USER=${MYSQL_USER}
      - MYSQL_PASSWORD=${MYSQL_PASSWORD}
    networks:
      - data_network

  minio:
    hostname: minio
    image: "minio/minio"
    container_name: minio
    ports:
      - "9001:9001"
      - "9000:9000"
    command: [ "server", "/data", "--console-address", ":9001" ]
    env_file:
      - .env
    networks:
      - data_network
  
  mc:
    image: minio/mc
    container_name: mc
    hostname: mc
    env_file:
      - .env
    entrypoint: >
      /bin/sh -c " until (/usr/bin/mc config host add minio http://minio:9000/ minio minio123) do echo '...waiting...' && sleep 10; done; /usr/bin/mc mb minio/mlflow; tail -f /dev/null;"
    depends_on:     
      - minio
    networks:
      - data_network

networks:
  data_network:
    driver: bridge
    name: data_network

  # de_dagster_dagit:
  #   build:
  #     context: ./docker_image/dagster
  #     dockerfile: Dockerfile
  #   entrypoint:
  #     - dagit
  #     - -h
  #     - "0.0.0.0"
  #     - -p
  #     - "3001"
  #     - -w
  #     - workspace.yaml
  #   container_name: de_dagster_dagit
  #   ports:
  #     - "3001:3001"
  #   volumes:
  #     - /var/run/docker.sock:/var/run/docker.sock
  #     - ./dagster_home:/opt/dagster/dagster_home
  #   env_file:
  #     - .env
  #   networks:
  #     - data_network
  #   depends_on:
  #     - de_psql

  # de_dagster_daemon:
  #   build:
  #     context: ./docker_image/dagster
  #     dockerfile: Dockerfile
  #   entrypoint:
  #     - dagster-daemon
  #     - run
  #   container_name: de_dagster_daemon
  #   volumes:
  #     - /var/run/docker.sock:/var/run/docker.sock
  #     - ./dagster_home:/opt/dagster/dagster_home
  #   env_file:
  #     - .env
  #   networks:
  #     - data_network
  #   depends_on:
  #     - de_psql

  # de_psql:
  #   image: postgres:14-alpine
  #   container_name: de_psql
  #   hostname: de_psql
  #   volumes:
  #     - ./pg_hba.conf:/tmp/pg_hba.conf
  #     # - ./load_dataset:/tmp/load_dataset
  #   command: ["postgres", "-c", "hba_file=/tmp/pg_hba.conf"]
  #   expose:
  #     - "5432"
  #   ports:
  #     - "5432:5432"
  #   env_file: 
  #     - .env
  #   networks:
  #     - data_network

#   etl_pipeline:
#     build:
#       context: ./etl_pipeline
#       dockerfile: Dockerfile
#     container_name: etl_pipeline
#     image: etl_pipeline:latest
#     user: root
#     volumes:
#       - ./etl_pipeline:/opt/dagster/app/etl_pipeline
#       - ./etl_pipeline/spark-defaults.conf:/usr/local/spark/conf/spark-defaults.conf
#     env_file:
#       - .env
#     expose:
#       - "4000"
#     networks:
#       - data_network

# networks:
#   data_network:
#     driver: bridge
#     name: data_network